<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><style>body {
  max-width: 980px;
  border: 1px solid #ddd;
  outline: 1300px solid #fff;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 45px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable,
.markdown-body .highlighttable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr,
.markdown-body .highlighttable {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite,
.markdown-body .highlighttable pre,
.markdown-body .highlighttable div.highlight {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td,
.markdown-body .highlighttable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headerlink {
  font: normal 400 16px fontawesome-mini;
  vertical-align: middle;
  margin-left: -16px;
  float: left;
  display: inline-block;
  text-decoration: none;
  opacity: 0;
  color: #333;
}

.markdown-body .headerlink:focus {
  outline: none;
}

.markdown-body h1 .headerlink {
  margin-top: 0.8rem;
}

.markdown-body h2 .headerlink,
.markdown-body h3 .headerlink {
  margin-top: 0.6rem;
}

.markdown-body h4 .headerlink {
  margin-top: 0.2rem;
}

.markdown-body h5 .headerlink,
.markdown-body h6 .headerlink {
  margin-top: 0;
}

.markdown-body .headerlink:hover,
.markdown-body h1:hover .headerlink,
.markdown-body h2:hover .headerlink,
.markdown-body h3:hover .headerlink,
.markdown-body h4:hover .headerlink,
.markdown-body h5:hover .headerlink,
.markdown-body h6:hover .headerlink {
  opacity: 1;
  text-decoration: none;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite,
.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body .highlight pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .codehilite pre,
.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* MultiMarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px fontawesome-mini;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\e157';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><script type='text/javascript' src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script><script>MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  extensions: ["tex2jax.js"],
  jax: ["input/TeX", "output/HTML-CSS", "output/NativeMML"],
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    processEnvironments: true,
    ignoreClass: ".*|",
    processClass: "arithmatex"
  },
  TeX: {
    extensions: ["AMSmath.js", "AMSsymbols.js"],
    TagSide: "right",
    TagIndent: ".8em",
    MultLineWidth: "85%",
    equationNumbers: {
      autoNumber: "AMS",
    },
    unicode: {
      fonts: "STIXGeneral,'Arial Unicode MS'"
    }
  },
  showProcessingMessages: false,
  messageStyle: 'none'
});
</script><style>/*GitHub*/
.highlight {background-color:#fff;color:#333333;}
.highlight .hll {background-color:#ffffcc;}
.highlight .c{color:#999988;font-style:italic}
.highlight .err{color:#a61717;background-color:#e3d2d2}
.highlight .k{font-weight:bold}
.highlight .o{font-weight:bold}
.highlight .cm{color:#999988;font-style:italic}
.highlight .cp{color:#999999;font-weight:bold}
.highlight .c1{color:#999988;font-style:italic}
.highlight .cs{color:#999999;font-weight:bold;font-style:italic}
.highlight .gd{color:#000000;background-color:#ffdddd}
.highlight .ge{font-style:italic}
.highlight .gr{color:#aa0000}
.highlight .gh{color:#999999}
.highlight .gi{color:#000000;background-color:#ddffdd}
.highlight .go{color:#888888}
.highlight .gp{color:#555555}
.highlight .gs{font-weight:bold}
.highlight .gu{color:#800080;font-weight:bold}
.highlight .gt{color:#aa0000}
.highlight .kc{font-weight:bold}
.highlight .kd{font-weight:bold}
.highlight .kn{font-weight:bold}
.highlight .kp{font-weight:bold}
.highlight .kr{font-weight:bold}
.highlight .kt{color:#445588;font-weight:bold}
.highlight .m{color:#009999}
.highlight .s{color:#dd1144}
.highlight .n{color:#333333}
.highlight .na{color:teal}
.highlight .nb{color:#0086b3}
.highlight .nc{color:#445588;font-weight:bold}
.highlight .no{color:teal}
.highlight .ni{color:purple}
.highlight .ne{color:#990000;font-weight:bold}
.highlight .nf{color:#990000;font-weight:bold}
.highlight .nn{color:#555555}
.highlight .nt{color:navy}
.highlight .nv{color:teal}
.highlight .ow{font-weight:bold}
.highlight .w{color:#bbbbbb}
.highlight .mf{color:#009999}
.highlight .mh{color:#009999}
.highlight .mi{color:#009999}
.highlight .mo{color:#009999}
.highlight .sb{color:#dd1144}
.highlight .sc{color:#dd1144}
.highlight .sd{color:#dd1144}
.highlight .s2{color:#dd1144}
.highlight .se{color:#dd1144}
.highlight .sh{color:#dd1144}
.highlight .si{color:#dd1144}
.highlight .sx{color:#dd1144}
.highlight .sr{color:#009926}
.highlight .s1{color:#dd1144}
.highlight .ss{color:#990073}
.highlight .bp{color:#999999}
.highlight .vc{color:teal}
.highlight .vg{color:teal}
.highlight .vi{color:teal}
.highlight .il{color:#009999}
.highlight .gc{color:#999;background-color:#EAF2F5}
</style><title>DRL</title></head><body><article class="markdown-body"><h1 id="the-foundations-of-deep-rl-in-6-lectures">The Foundations of Deep RL in 6 Lectures<a class="headerlink" href="#the-foundations-of-deep-rl-in-6-lectures" title="Permanent link"></a></h1>
<p>This lecture is given by <a href="https://en.wikipedia.org/wiki/Pieter_Abbeel">Pieter Abbeel</a></p>
<h1 id="l1-mdps-exact-solution-methods-max-ent-rl">L1 MDPs, Exact Solution Methods, Max-ent RL<a class="headerlink" href="#l1-mdps-exact-solution-methods-max-ent-rl" title="Permanent link"></a></h1>
<hr />
<h2 id="lecture-series">Lecture Series<a class="headerlink" href="#lecture-series" title="Permanent link"></a></h2>
<ul>
<li>Lecture 1: MDPs Foundations and Exact Solution Methods</li>
<li>Lecture 2: Deep Q-Learning</li>
<li>Lecture 3: Policy Gradients, Advantage Estimation</li>
<li>Lecture 4: TRPO, PPO</li>
<li>Lecture 5: DDPG, SAC</li>
<li>Lecture 6: Model-based RL</li>
</ul>
<hr />
<h2 id="outline-for-this-lecture">Outline for This Lecture<a class="headerlink" href="#outline-for-this-lecture" title="Permanent link"></a></h2>
<ul>
<li>Motication</li>
<li>Markov Decision Processes</li>
<li>Exact Solution Methods<ul>
<li>Value Iteration</li>
<li>Policy Iteration</li>
</ul>
</li>
<li>Maximum Entropy Formulation</li>
</ul>
<hr />
<h2 id="a-few-deep-rl-highlights">A Few Deep RL Highlights<a class="headerlink" href="#a-few-deep-rl-highlights" title="Permanent link"></a></h2>
<ul>
<li>Atari (DQN) [Deepmind] - 2013<ul>
<li>Video games, including Pong, Enduro, Beamrider, Q*bert</li>
</ul>
</li>
<li>2D locomotion (TRPO) [Berkley]</li>
<li>AlphaGo [Deepmind]<ul>
<li>Tian et al, 2016</li>
<li>Maddison et al, 2014</li>
<li>Clark et al, 2015</li>
</ul>
</li>
<li>3D locamotion (TRPO+GAE) [Berkley]<ul>
<li>[Shulman, Moitz, Levine, Jordan, Abbeel, ICLR 2016]</li>
</ul>
</li>
<li>Real Robot Manipulation (GPS) [Berkley]<ul>
<li>[Levine<em>, Finn</em>, Darrell, Abbeel, JMLR 2016]</li>
</ul>
</li>
<li>Dota2 (PPO) [OpenAI]<ul>
<li>OpenAI Dota Bot beat best humans 1:1 (Aug 2018)</li>
</ul>
</li>
<li>DeepMimic [Berkley]</li>
<li>AlphaStar [Deepmind] 2019</li>
<li>Rubik's Cube (PPO+DR) [OpenAI]</li>
</ul>
<hr />
<h2 id="markov-decision-process">Markov Decision Process<a class="headerlink" href="#markov-decision-process" title="Permanent link"></a></h2>
<ul>
<li>Agent -&gt; Environment (action <span class="arithmatex">\(a_t\)</span>)</li>
<li>Environment -&gt; Agent (state <span class="arithmatex">\(s_t\)</span>)</li>
<li>Environment -&gt; Agent (reward <span class="arithmatex">\(r_t\)</span>)</li>
</ul>
<p>This is an iterative process, in next iteration will have <span class="arithmatex">\(t_{t+1}\)</span>, <span class="arithmatex">\(r_{t+1}\)</span>. </p>
<p>Assumption: agent gets to observe the state</p>
<p>[Drawing from Sutton and Barto, Reinforcement Learning: An Introduction, 1998]</p>
<hr />
<h2 id="markov-decision-process-mdp">Markov Decision Process (MDP)<a class="headerlink" href="#markov-decision-process-mdp" title="Permanent link"></a></h2>
<ul>
<li>An MDP is (formally) defined by:<ul>
<li>Set of states <span class="arithmatex">\(S\)</span></li>
<li>Set of actions <span class="arithmatex">\(A\)</span></li>
<li>Transition function <span class="arithmatex">\(P(s'|s,a)\)</span><ul>
<li>The probability <span class="arithmatex">\(P\)</span> of </li>
<li><span class="arithmatex">\(s'\)</span> next state</li>
<li>given current state <span class="arithmatex">\(s\)</span> and </li>
<li>took action <span class="arithmatex">\(a\)</span></li>
</ul>
</li>
<li>Reward function <span class="arithmatex">\(R(s, a, s')\)</span></li>
<li>Start state <span class="arithmatex">\(s_0\)</span></li>
<li>Discount factor <span class="arithmatex">\(\gamma\)</span><ul>
<li>used for discounting the future reward</li>
</ul>
</li>
<li>Horizon <span class="arithmatex">\(H\)</span><ul>
<li>how long we gonna act</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr />
<h2 id="examples">Examples<a class="headerlink" href="#examples" title="Permanent link"></a></h2>
<p><span class="arithmatex">\(MDP(S,A,T,R,\gamma,H)\)</span>,</p>
<p><strong>goal</strong>: <span class="arithmatex">\(max_{\pi}E[\sum_{t=0}^H \gamma^t R(S_t,A_t,S_{t+1})|\pi]\)</span></p>
<p>The goal for the reinforcement algorithm is to maximize <span class="arithmatex">\(max_\pi(...)\)</span>  the expected <span class="arithmatex">\(E(...)\)</span> discounted reward <span class="arithmatex">\(\gamma^tR(...)\)</span> over time <span class="arithmatex">\(t=[0 .. H]\)</span></p>
<ul>
<li>Cleaning robot</li>
<li>Walking robot</li>
<li>Pole balancing</li>
<li>Games: tetris, backgammon</li>
<li>Server management</li>
<li>Shortest path problems</li>
<li>Model for animals, people</li>
</ul>
<p>What you need to do is to map your problem onto the MDP, and you can run your algorithm</p>
<hr />
<h2 id="example-mdp-gridworld">Example MDP: Gridworld<a class="headerlink" href="#example-mdp-gridworld" title="Permanent link"></a></h2>
<p>Simple environment</p>
<ul>
<li>Start</li>
<li>Agent - robot</li>
<li>Rock</li>
<li>Reward (+1)</li>
<li>Fire (-1)</li>
</ul>
<p><strong>goal</strong>: <span class="arithmatex">\(max_{\pi}E[\sum_{t=0}^H \gamma^t R(S_t,A_t,S_{t+1})|\pi]\)</span></p>
<hr />
<h2 id="optimal-value-function-v">Optimal Value Function V*<a class="headerlink" href="#optimal-value-function-v" title="Permanent link"></a></h2>
<p><em>Value intuition which will be foundations of many models we talk later</em></p>
<p><span class="arithmatex">\(V^*(s)= max_{\pi}E[\sum_{t=0}^H\gamma^tR(s_t,a_t,s_{t+1})|\pi,s_0=s]\)</span></p>
<p>= sum of discounted rewards when starting from state s and acting optimally</p>
<p>Best possible policy <span class="arithmatex">\(max_{\pi}\)</span></p>
<p>Let's assume:</p>
<p>actions deterministically successful, <span class="arithmatex">\(\gamma=0.9\)</span>, <span class="arithmatex">\(H=100\)</span></p>
<p><span class="arithmatex">\(V^*(4,3)=1\)</span></p>
<p><span class="arithmatex">\(V^*(3,3)=0.9\)</span></p>
<p><span class="arithmatex">\(V^*(2,3)=0.9*0.9=0.81\)</span></p>
<p><span class="arithmatex">\(V^*(1,1)=0.9*0.9*0.9*0.9*0.9=0.59\)</span></p>
<p><span class="arithmatex">\(V^*(4,2)=-1\)</span></p>
<p>actions successful w/probablity 0.8, <span class="arithmatex">\(\gamma=0.9\)</span>, <span class="arithmatex">\(H=100\)</span></p>
<p><span class="arithmatex">\(V^*(4,3)=1\)</span></p>
<p><span class="arithmatex">\(V^*(3,3)=0.8 * 0.9 * V^*(4,3)+0.1*0.9*V^*(3,3) + 0.1*0.9*V^*(3,2)\)</span></p>
<p><span class="arithmatex">\(V^*(2,3)=\)</span></p>
<p><span class="arithmatex">\(V^*(1,1)=\)</span></p>
<p><span class="arithmatex">\(V^*(4,2)=\)</span></p>
<hr />
<h2 id="value-iteration">Value Iteration<a class="headerlink" href="#value-iteration" title="Permanent link"></a></h2>
<ul>
<li><span class="arithmatex">\(V^*_0(s)\)</span> = optimal value for state <span class="arithmatex">\(s\)</span> when <span class="arithmatex">\(H=0\)</span><ul>
<li><span class="arithmatex">\(V^*_0(s)=0\)</span>   <span class="arithmatex">\(\forall s\)</span><ul>
<li>we can initialize the value for all states as 0</li>
</ul>
</li>
</ul>
</li>
<li><span class="arithmatex">\(V^*_1(s)\)</span> = optimal value for state <span class="arithmatex">\(s\)</span> when <span class="arithmatex">\(H=1\)</span><ul>
<li><span class="arithmatex">\(V^*_{1}(s)=max_{a}\sum_{s'}P(s'|s,a)(R(s,a,s')+\gamma V^*_0(s'))\)</span><ul>
<li>We look at all actions available in that state <span class="arithmatex">\(P(s'|s,a)\)</span></li>
<li>Then sum over all future states the probability for future as <span class="arithmatex">\(s'\)</span></li>
<li>given the current <span class="arithmatex">\(s\)</span>, took action <span class="arithmatex">\(a\)</span></li>
<li>multiply with the reward we get from that transition <span class="arithmatex">\(R(s,a,s')\)</span></li>
<li>plus a discount factor <span class="arithmatex">\(\gamma V^*_0(s')\)</span></li>
<li>the value get on forth and on forth from the zero point</li>
</ul>
</li>
<li>this is really the key idea behind value iteration, is that:<ul>
<li>you decompose the promises thing a certain number of times into the immediate thing</li>
</ul>
</li>
</ul>
</li>
<li><span class="arithmatex">\(V^*_2(s)\)</span> = optimal value for state <span class="arithmatex">\(s\)</span> when <span class="arithmatex">\(H=2\)</span><ul>
<li><span class="arithmatex">\(V^*_{2}(s)=max_{a}\sum_{s'}P(s'|s,a)(R(s,a,s')+\gamma V^*_1(s'))\)</span></li>
</ul>
</li>
<li><span class="arithmatex">\(V^*_k(s)\)</span> = optimal value for state <span class="arithmatex">\(s\)</span> when <span class="arithmatex">\(H=k\)</span><ul>
<li><span class="arithmatex">\(V^*_{k}(s)=max_{a}\sum_{s'}P(s'|s,a)(R(s,a,s')+\gamma V^*_{k-1}(s'))\)</span></li>
</ul>
</li>
</ul>
<hr />
<h2 id="value-iteration_1">Value Iteration<a class="headerlink" href="#value-iteration_1" title="Permanent link"></a></h2>
<ul>
<li>Algorithm<ul>
<li>Start with <span class="arithmatex">\(V^*_0(s)=0\)</span> for all <span class="arithmatex">\(s\)</span>.</li>
<li>For k=1, ..., H:<ul>
<li>For all states s in S:</li>
<li><span class="arithmatex">\(V^*_{k}(s) \leftarrow max_{a}\sum_{s'}P(s'|s,a)(R(s,a,s')+\gamma V^*_{k-1}(s'))\)</span></li>
<li><span class="arithmatex">\(\pi^*_k(s) \leftarrow argmax_{a}\sum_{s'}P(s'|s,a)(R(s,a,s')+\gamma V^*_{k-1}(s'))\)</span><ul>
<li>This is called a <strong>value update</strong> or <strong>Bellman update/back-up</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><span class="arithmatex">\(V^*_{k}(s)=max_{a}\sum_{s'}P(s'|s,a)(R(s,a,s')+\gamma V^*_{k-1}(s'))\)</span></p>
<p><img alt="VALUES AFTER 100 ITERATIONS" src="/Users/admin/Documents/notes/DRL/001-010.png" /></p>
<ul>
<li>As it is shown to you, if we run infinitve Horizon value, we will get the above. It converges to that or very close to that much sooner.</li>
<li>The speed of convergence is often related to the discount factor <span class="arithmatex">\(\gamma\)</span>. The close the discount is to 0, the faster the things converges. The close the discount is to 1, the longer it might take, for things to converge</li>
</ul>
<hr />
<h2 id="value-iteration-convergence">Value Iteration Convergence<a class="headerlink" href="#value-iteration-convergence" title="Permanent link"></a></h2>
<p><strong>Theorem.</strong> Value iteration converges. At convergence, we have found the optimal value function <span class="arithmatex">\(V^*\)</span> for the discounted infinite horizon problem, which satisified the Bellman equations</p>
<p><span class="arithmatex">\(\forall S \in S\)</span> : <span class="arithmatex">\(V^*_{k}(s)=max_{A}\sum_{s'}P(s'|s,a)(R(s,a,s')+\gamma V^*_{k-1}(s'))\)</span></p>
<ul>
<li>Now we know how to act for infinite horizon with discounted rewards!<ul>
<li>Run value iteration till convergence.</li>
<li>This produces <span class="arithmatex">\(V^*\)</span>, which in turn tells us how to act, namely following:</li>
<li><span class="arithmatex">\(\pi^*(s) = argmax_{a\in A}\sum_{s'}T(s,a,s')[R(s,a,s')+\gamma V^*(s')*]\)</span></li>
<li>and this produces <span class="arithmatex">\(V^*\)</span>, and then, once we have <span class="arithmatex">\(V^*\)</span>, we will be able to extract actual optimal action using the Bellman equation, yet one more time, or we might have just stored the optimal action for our Bellman updates during running the algorithm.</li>
</ul>
</li>
<li>Notes: the infinite horizon optimal policy is stationary, i.e., the optimal action at a state <span class="arithmatex">\(s\)</span> is the same action at all times. (Efficient to store!)</li>
</ul>
<hr />
<h2 id="convergence-intuition">Convergence: Intuition<a class="headerlink" href="#convergence-intuition" title="Permanent link"></a></h2>
<p>Why do we know this is going to converge</p>
<ul>
<li><span class="arithmatex">\(V^*(s)\)</span> = expected sum of rewards accumulated starting from state <span class="arithmatex">\(s\)</span>, acting optimally for <span class="arithmatex">\(\infty\)</span> steps</li>
<li><span class="arithmatex">\(V^*_H(s)\)</span> = expected sum of rewards accumulated starting from state <span class="arithmatex">\(s\)</span>, acting optimally for <span class="arithmatex">\(H\)</span> steps</li>
<li>Additional reward collected over time steps <span class="arithmatex">\(H+1\)</span>, <span class="arithmatex">\(H+2\)</span>, ...<ul>
<li><span class="arithmatex">\(\gamma^{H+1}R(s_{H+1})+\gamma^{H+2}R(s_{H+2})+...\le \gamma^{H+1}R_{max}+\gamma^{H+2}R_{max}+...\)</span></li>
<li><span class="arithmatex">\(= \frac{\gamma^{H+1}}{1-\gamma} R_{max}\)</span></li>
<li>goes to zero as <span class="arithmatex">\(H\)</span> goes to infinity</li>
<li>Hence <span class="arithmatex">\(V^*_H \overset{H\rightarrow\infty}\rightarrow V^*\)</span></li>
</ul>
</li>
</ul>
<p>For simplicity of notation in the above it was assumed that rewards are always greater than or equal to zero. If rewards can be negative, a similar argument holds, using <span class="arithmatex">\(max|R|\)</span> and bounding from both sides. </p>
<hr />
<h2 id="convergence-and-contractions">Convergence and Contractions<a class="headerlink" href="#convergence-and-contractions" title="Permanent link"></a></h2>
<ul>
<li>Definition: max-norm: <span class="arithmatex">\(||U||= max_s|U(s)|\)</span></li>
<li>Definition: An update operation is a <span class="arithmatex">\(\gamma\)</span>-contraction in max-norm if and only if for all <span class="arithmatex">\(U_{i}\)</span>, <span class="arithmatex">\(V^*_{i}\)</span> :<ul>
<li><span class="arithmatex">\(||U_{i+1}-V_{i+1}||\le\gamma||U_i-V_i||\)</span></li>
</ul>
</li>
<li>Theorem: A contraction converges to a unique fixed point, no matter initialization.</li>
<li>Fact: the value iteration update is a <span class="arithmatex">\(\gamma\)</span>-contraction in max-norm</li>
<li>Corollary: value iteration converges to a unique fixed point</li>
<li>Additional fact: <span class="arithmatex">\(||V_{i+1}-V_{i+1}||&lt;\epsilon\)</span>, <span class="arithmatex">\(\Rightarrow\)</span> <span class="arithmatex">\(||V_{i+1}-V^*||&lt;2\epsilon\gamma/(1-\gamma)\)</span><ul>
<li>i.e. once the update is small, it must also be close to converged</li>
</ul>
</li>
</ul>
<hr />
<h2 id="exercise-1-effect-of-discount-and-noise">Exercise 1: Effect of Discount and Noise<a class="headerlink" href="#exercise-1-effect-of-discount-and-noise" title="Permanent link"></a></h2>
<p><img alt="" src="/Users/admin/Documents/notes/DRL/001-011.png" /></p>
<ul>
<li>Start conditions<ul>
<li>(a) Prefer the close exit(+1), risking the cliff(-10)</li>
<li>(b) Prefer the close exit(+1), but avoid the cliff(-10)</li>
<li>(c) Prefer the distant exit(+10), risking the cliff(-10)</li>
<li>(d) Prefer thee distant exit(+10), avoiding the cliff(-10)</li>
</ul>
</li>
<li>Parameters<ul>
<li>(1) <span class="arithmatex">\(\gamma=0.1\)</span>, noise=0.5</li>
<li>(2) <span class="arithmatex">\(\gamma=0.99\)</span>, noise=0</li>
<li>(3) <span class="arithmatex">\(\gamma=0.99\)</span>, noise=0.5</li>
<li>(4) <span class="arithmatex">\(\gamma=0.1\)</span>, noise=0</li>
</ul>
</li>
</ul>
<p>Note: once you get the reward, the game is over. So you can just get any of 1 or 10 reward. The exercise is to figure out for (a) from (1) .. (4), which is the optimal</p>
<hr />
<h2 id="exercise-1-solution">Exercise 1 Solution<a class="headerlink" href="#exercise-1-solution" title="Permanent link"></a></h2>
<p><img alt="" src="/Users/admin/Documents/notes/DRL/001-012.png" /></p>
<ul>
<li>(a) Prefer the close exit(+1), risking the cliff(-10)</li>
<li>(4) <span class="arithmatex">\(\gamma=0.1\)</span>, noise=0<ul>
<li>noise = 0, means dont take any risk</li>
<li>There's 0.0 chance of your action being unsuccessful</li>
<li>If the noise is &gt;0.0, which means in some circumstance(random()&gt;1-noise), the action will be randomed</li>
<li>In this way, you can safely navigate to the distant exit</li>
<li>And we shall make sure to discount enough to ensure the agent goes to the distant exit</li>
<li>The grey block is cliff, the red block is fire</li>
</ul>
</li>
</ul>
<p><img alt="" src="/Users/admin/Documents/notes/DRL/001-013.png" /></p>
<ul>
<li>(b) Prefer the close exit(+1), but avoid the cliff(-10)</li>
<li>(1) <span class="arithmatex">\(\gamma=0.1\)</span>, noise=0.5</li>
</ul>
<p><img alt="" src="/Users/admin/Documents/notes/DRL/001-014.png" /></p>
<ul>
<li>(c) Prefer the distant exit(+10), risking the cliff(-10)</li>
<li>(2) <span class="arithmatex">\(\gamma=0.99\)</span>, noise=0</li>
</ul>
<p><img alt="" src="/Users/admin/Documents/notes/DRL/001-015.png" /></p>
<ul>
<li>(d) Prefer thee distant exit(+10), avoiding the cliff(-10)</li>
<li>(3) <span class="arithmatex">\(\gamma=0.99\)</span>, noise=0.5</li>
</ul>
<hr />
<h2 id="q-values">Q-Values<a class="headerlink" href="#q-values" title="Permanent link"></a></h2>
<p><span class="arithmatex">\(Q^*(s,a)\)</span> = expected utility starting in <span class="arithmatex">\(s\)</span>, taking action <span class="arithmatex">\(a\)</span>, and (thereafter) acting optimally</p>
<p>Bellman Equation:</p>
<p><span class="arithmatex">\(Q^*(s,a)=\sum_{s'}P(s'|s,a)(R(s,a,s')+\gamma \max_{a'}Q^*(s', a'))\)</span></p>
<p>Q-Value Iteration:</p>
<p><span class="arithmatex">\(Q^*_{k+1}(s,a)=\sum_{s'}P(s'|s,a)(R(s,a,s')+\gamma \max_{a'}Q^*_k(s', a'))\)</span></p>
<p>resume at 45:30</p>
<hr />
<p><a href="https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56">Simple Reinforcement Learning: Q-learning</a></p>
<h2 id="whats-q">What’s ‘Q’?<a class="headerlink" href="#whats-q" title="Permanent link"></a></h2>
<p>The ‘q’ in q-learning stands for quality. Quality in this case represents how useful a given action is in gaining some future reward.</p></article></body></html>